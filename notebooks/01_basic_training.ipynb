{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Drone Training with PPO\n",
    "\n",
    "This notebook demonstrates how to train a drone using PPO algorithm.\n",
    "\n",
    "## Quick Start\n",
    "1. Import training functions\n",
    "2. Configure training parameters\n",
    "3. Train the model\n",
    "4. Test the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path if needed\n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Import training utilities\n",
    "from train.simple_train import train_ppo, train_sac, load_model\n",
    "from train.config import TrainingConfig\n",
    "from train.test_utils import test_model, quick_test, visualize_episode\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quick Test (Optional)\n",
    "\n",
    "Test the environment before training to make sure everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick environment test\n",
    "from crazy_flie_env import CrazyFlieEnv\n",
    "\n",
    "env = CrazyFlieEnv()\n",
    "obs, info = env.reset()\n",
    "\n",
    "print(f\"Observation space: {env.observation_space}\")\n",
    "print(f\"Action space: {env.action_space}\")\n",
    "print(f\"State shape: {obs['state'].shape}\")\n",
    "print(f\"Image shape: {obs['image'].shape}\")\n",
    "\n",
    "# Test one step\n",
    "action = env.action_space.sample()\n",
    "obs, reward, terminated, truncated, info = env.step(action)\n",
    "print(f\"Step completed! Reward: {reward:.3f}\")\n",
    "\n",
    "env.close()\n",
    "print(\"\\n‚úÖ Environment test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Training\n",
    "\n",
    "Create a training configuration. You can modify any parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training (for testing)\n",
    "config = TrainingConfig(\n",
    "    algorithm=\"PPO\",\n",
    "    total_timesteps=100_000,  # Short for testing\n",
    "    num_envs=4,\n",
    "    learning_rate=3e-4,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    eval_freq=10_000,\n",
    "    save_freq=20_000\n",
    ")\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Algorithm: {config.algorithm}\")\n",
    "print(f\"  Total timesteps: {config.total_timesteps:,}\")\n",
    "print(f\"  Parallel envs: {config.num_envs}\")\n",
    "print(f\"  Learning rate: {config.learning_rate}\")\n",
    "print(f\"  Device: {config.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train PPO Agent\n",
    "\n",
    "This will train the agent. Progress bar will show training progress.\n",
    "\n",
    "‚ö†Ô∏è **Note**: Training can take a while depending on `total_timesteps`.\n",
    "- 100K steps: ~10-30 minutes\n",
    "- 500K steps: ~1-2 hours\n",
    "- 1M steps: ~2-4 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model, results = train_ppo(config, verbose=True)\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")\n",
    "print(f\"Model saved to: {results['final_model_path']}\")\n",
    "print(f\"Logs available at: {results['log_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test the Trained Model\n",
    "\n",
    "Test the trained model on several episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model (will render first 3 episodes)\n",
    "avg_reward, metrics = test_model(\n",
    "    model_path=results['final_model_path'],\n",
    "    algorithm=\"PPO\",\n",
    "    num_episodes=10,\n",
    "    render=True\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Test Results:\")\n",
    "print(f\"  Average Reward: {metrics['avg_reward']:.2f}\")\n",
    "print(f\"  Std Dev: {metrics['std_reward']:.2f}\")\n",
    "print(f\"  Success Rate: {metrics['success_rate']:.1%}\")\n",
    "print(f\"  Average Episode Length: {metrics['avg_length']:.1f} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View Training Logs with TensorBoard\n",
    "\n",
    "Run this cell to view training metrics in TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Launch TensorBoard\n",
    "%tensorboard --logdir logs/\n",
    "\n",
    "# Alternatively, run this in terminal:\n",
    "# tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Episode Trajectory (Optional)\n",
    "\n",
    "Visualize the drone's trajectory during an episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Get trajectory data\n",
    "trajectory = visualize_episode(\n",
    "    model_path=results['final_model_path'],\n",
    "    algorithm=\"PPO\",\n",
    "    max_steps=500\n",
    ")\n",
    "\n",
    "# Extract positions\n",
    "positions = [t['position'] for t in trajectory]\n",
    "positions = np.array(positions)\n",
    "\n",
    "# Plot 3D trajectory\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.plot(positions[:, 0], positions[:, 1], positions[:, 2], 'b-', linewidth=2, alpha=0.7)\n",
    "ax.scatter(positions[0, 0], positions[0, 1], positions[0, 2], c='g', s=100, label='Start')\n",
    "ax.scatter(positions[-1, 0], positions[-1, 1], positions[-1, 2], c='r', s=100, label='End')\n",
    "\n",
    "ax.set_xlabel('X Position (m)')\n",
    "ax.set_ylabel('Y Position (m)')\n",
    "ax.set_zlabel('Z Position (m)')\n",
    "ax.set_title('Drone Flight Trajectory')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Episode completed in {len(trajectory)} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train SAC Agent (Alternative)\n",
    "\n",
    "If you want to try SAC instead of PPO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure for SAC\n",
    "sac_config = TrainingConfig(\n",
    "    algorithm=\"SAC\",\n",
    "    total_timesteps=100_000,\n",
    "    num_envs=4,\n",
    "    learning_rate=3e-4,\n",
    "    batch_size=256,\n",
    "    buffer_size=100_000\n",
    ")\n",
    "\n",
    "# Train SAC\n",
    "sac_model, sac_results = train_sac(sac_config, verbose=True)\n",
    "\n",
    "# Test SAC\n",
    "test_model(\n",
    "    model_path=sac_results['final_model_path'],\n",
    "    algorithm=\"SAC\",\n",
    "    num_episodes=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Longer training**: Increase `total_timesteps` to 500K or 1M for better performance\n",
    "- **Hyperparameter tuning**: Experiment with learning rate, batch size, etc.\n",
    "- **Custom rewards**: Modify the environment reward function\n",
    "- **Different algorithms**: Try SAC, A2C, or custom algorithms\n",
    "- **Advanced features**: Add curriculum learning, domain randomization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
